Writing "C" code to encode and decode H.264 by using libavcodec
This example implement base on api-example source code. It will show you how to write "C" code to encode raw data (qcif) to h264 and decoded it to yuv.

Part of the main code is shown below.

int main(int argc, char **argv)
{

/* must be called before using avcodec lib */
avcodec_init();

/* register all the codecs */
avcodec_register_all();

h264_encode_decode("Foreman.qcif","Decoded.yuv");

return 0;
}

We start with registering and initialize codec. And then we call function h264_encode_decode(), this function will encode input file ("Foreman.qcif") to h.264 and then decode it to yuv file ("Decoded.yuv").

I will divide h264_encode_decode function into 5 steps.

1. Declare variable that use in decode and encode.

AVCodec *codecEncode, *codecDecode;
AVCodecContext *ctxEncode= NULL, *ctxDecode = NULL;

FILE *fin, *fout;
AVFrame *pictureEncoded, *pictureDecoded;

uint8_t *encoderOut, *picEncodeBuf;
int encoderOutSize, decoderOutSize;
int pic_size;

AVPacket avpkt;
int got_picture, len;

const int clip_width = 176;
const int clip_height = 144;

int frame = 0;
uint8_t *decodedOut;


2. Initial codec/picture structure for decoder.

codecDecode = avcodec_find_decoder(CODEC_ID_H264);
if (!codecDecode) {
fprintf(stderr, "codec not found\n");
exit(1);
}

ctxDecode= avcodec_alloc_context();
avcodec_get_context_defaults(ctxDecode);
ctxDecode->flags2 |= CODEC_FLAG2_FAST;
ctxDecode->pix_fmt = PIX_FMT_YUV420P;
ctxDecode->width = clip_width;
ctxDecode->height = clip_height;
ctxDecode->dsp_mask = (FF_MM_MMX | FF_MM_MMXEXT | FF_MM_SSE);

if (avcodec_open(ctxDecode, codecDecode) < 0) {
fprintf(stderr, "could not open codec\n");
exit(1);
}

pictureDecoded= avcodec_alloc_frame();
avcodec_get_frame_defaults(pictureDecoded);
pic_size = avpicture_get_size(PIX_FMT_YUV420P, clip_width, clip_height);

decodedOut = (uint8_t *)malloc(pic_size);
fout = fopen(fileout, "wb");
if (!fout) {
fprintf(stderr, "could not open %s\n", fileout);
exit(1);
}


3. Initial codec/picture for encoder.

codecEncode = avcodec_find_encoder(CODEC_ID_H264);
if (!codecEncode) {
printf("codec not found\n");
exit(1);
}

ctxEncode= avcodec_alloc_context();
ctxEncode->coder_type = 0; // coder = 1
ctxEncode->flags|=CODEC_FLAG_LOOP_FILTER; // flags=+loop
ctxEncode->me_cmp|= 1; // cmp=+chroma, where CHROMA = 1
ctxEncode->partitions|=X264_PART_I8X8+X264_PART_I4X4+X264_PART_P8X8+X264_PART_B8X8; // partitions=+parti8x8+parti4x4+partp8x8+partb8x8
ctxEncode->me_method=ME_HEX; // me_method=hex
ctxEncode->me_subpel_quality = 0; // subq=7
ctxEncode->me_range = 16; // me_range=16
ctxEncode->gop_size = 30*3; // g=250
ctxEncode->keyint_min = 30; // keyint_min=25
ctxEncode->scenechange_threshold = 40; // sc_threshold=40
ctxEncode->i_quant_factor = 0.71; // i_qfactor=0.71
ctxEncode->b_frame_strategy = 1; // b_strategy=1
ctxEncode->qcompress = 0.6; // qcomp=0.6
ctxEncode->qmin = 0; // qmin=10
ctxEncode->qmax = 69; // qmax=51
ctxEncode->max_qdiff = 4; // qdiff=4
ctxEncode->max_b_frames = 3; // bf=3
ctxEncode->refs = 3; // refs=3
ctxEncode->directpred = 1; // directpred=1
ctxEncode->trellis = 1; // trellis=1
ctxEncode->flags2|=CODEC_FLAG2_FASTPSKIP; // flags2=+bpyramid+mixed_refs+wpred+dct8x8+fastpskip
ctxEncode->weighted_p_pred = 0; // wpredp=2
ctxEncode->bit_rate = 32000;
ctxEncode->width = clip_width;
ctxEncode->height = clip_height;
ctxEncode->time_base.num = 1;
ctxEncode->time_base.den = 30;
ctxEncode->pix_fmt = PIX_FMT_YUV420P;
ctxEncode->dsp_mask = (FF_MM_MMX | FF_MM_MMXEXT | FF_MM_SSE);
ctxEncode->rc_lookahead = 0;
ctxEncode->max_b_frames = 0;
ctxEncode->b_frame_strategy =1;
ctxEncode->chromaoffset = 0;
ctxEncode->thread_count =1;
ctxEncode->bit_rate = (int)(128000.f * 0.80f);
ctxEncode->bit_rate_tolerance = (int) (128000.f * 0.20f);
ctxEncode->gop_size = 30*3; // Each 3 seconds

/* open codec for encoder*/
if (avcodec_open(ctxEncode, codecEncode) < 0) {
printf("could not open codec\n");
exit(1);
}

//open file to read
fin = fopen(filein, "rb");
if (!fin) {
printf("could not open %s\n", filein);
exit(1);
}

/* alloc image and output buffer for encoder*/
pictureEncoded= avcodec_alloc_frame();
avcodec_get_frame_defaults(pictureEncoded);

//encoderOutSize = 100000;
encoderOut = (uint8_t *)malloc(100000);
//int size = ctxEncode->width * ctxEncode->height;
picEncodeBuf = (uint8_t *)malloc(3*pic_size/2); /* size for YUV 420 */
pictureEncoded->data[0] = picEncodeBuf;
pictureEncoded->data[1] = pictureEncoded->data[0] + pic_size;
pictureEncoded->data[2] = pictureEncoded->data[1] + pic_size / 4;
pictureEncoded->linesize[0] = ctxEncode->width;
pictureEncoded->linesize[1] = ctxEncode->width / 2;
pictureEncoded->linesize[2] = ctxEncode->width / 2;

4. Read data from input file and encode it by using avcodec_encode_video, encoded data will send to decode to yuv format by using avcodec_decode_video2. Decoded data will be written to decoded.yuv file.

//encode and decode loop
for(int i=0;i<30;i++)
{
fflush(stdout);
//read qcif 1 frame to buufer
fread(pictureEncoded->data[0],ctxEncode->width * ctxEncode->height, 1, fin);
fread(pictureEncoded->data[1],ctxEncode->width * ctxEncode->height/4, 1, fin);
fread(pictureEncoded->data[2],ctxEncode->width * ctxEncode->height/4, 1, fin);
pictureEncoded->pts = AV_NOPTS_VALUE;

/* encode frame */
encoderOutSize = avcodec_encode_video(ctxEncode, encoderOut, 100000, pictureEncoded);
printf("encoding frame %3d (size=%5d)\n", i, encoderOutSize);
if(encoderOutSize <= 0)
continue;

//send encoderOut to decoder
avpkt.size = encoderOutSize;
avpkt.data = encoderOut;
//decode frame
len = avcodec_decode_video2(ctxDecode, pictureDecoded, &got_picture, &avpkt);
if (len < 0) {
printf("Error while decoding frame %d\n", frame);
exit(1);
}
if (got_picture) {
printf("len = %d saving frame %3d\n", len, frame);
fflush(stdout);

avpicture_layout((AVPicture *)pictureDecoded, ctxDecode->pix_fmt
, clip_width, clip_height, decodedOut, pic_size);
fwrite(decodedOut, pic_size, 1, fout);
frame++;
}
}


5. Free allocated memory and close file pointer.

fclose(fout);
fclose(fin);

avcodec_close(ctxEncode);
avcodec_close(ctxDecode);
av_free(ctxEncode);
av_free(ctxDecode);
av_free(pictureEncoded);
av_free(pictureDecoded);
======

/**
 * @file
 * libavcodec API use example.
 *
 * Note that libavcodec only handles codecs (mpeg, mpeg4, etc...),
 * not file formats (avi, vob, mp4, mov, mkv, mxf, flv, mpegts, mpegps, etc...).
 * See library 'libavformat' for the format handling
 * @example doc/examples/decoding_encoding.c
 */

#include <math.h>

#include <libavutil/opt.h>
#include <libavcodec/avcodec.h>
#include <libavutil/channel_layout.h>
#include <libavutil/common.h>
#include <libavutil/imgutils.h>
#include <libavutil/mathematics.h>
#include <libavutil/samplefmt.h>

#define INBUF_SIZE 4096
#define AUDIO_INBUF_SIZE 20480
#define AUDIO_REFILL_THRESH 4096

/* check that a given sample format is supported by the encoder */
static int check_sample_fmt(AVCodec *codec, enum AVSampleFormat sample_fmt)
{
    const enum AVSampleFormat *p = codec->sample_fmts;

    while (*p != AV_SAMPLE_FMT_NONE) {
        if (*p == sample_fmt)
            return 1;
        p++;
    }
    return 0;
}

/* just pick the highest supported samplerate */
static int select_sample_rate(AVCodec *codec)
{
    const int *p;
    int best_samplerate = 0;

    if (!codec->supported_samplerates)
        return 44100;

    p = codec->supported_samplerates;
    while (*p) {
        best_samplerate = FFMAX(*p, best_samplerate);
        p++;
    }
    return best_samplerate;
}

/* select layout with the highest channel count */
static int select_channel_layout(AVCodec *codec)
{
    const uint64_t *p;
    uint64_t best_ch_layout = 0;
    int best_nb_channells   = 0;

    if (!codec->channel_layouts)
        return AV_CH_LAYOUT_STEREO;

    p = codec->channel_layouts;
    while (*p) {
        int nb_channels = av_get_channel_layout_nb_channels(*p);

        if (nb_channels > best_nb_channells) {
            best_ch_layout    = *p;
            best_nb_channells = nb_channels;
        }
        p++;
    }
    return best_ch_layout;
}

/*
 * Audio encoding example
 */
static void audio_encode_example(const char *filename)
{
    AVCodec *codec;
    AVCodecContext *c= NULL;
    AVFrame *frame;
    AVPacket pkt;
    int i, j, k, ret, got_output;
    int buffer_size;
    FILE *f;
    uint16_t *samples;
    float t, tincr;

    printf("Encode audio file %s\n", filename);

    /* find the MP2 encoder */
    codec = avcodec_find_encoder(AV_CODEC_ID_MP2);
    if (!codec) {
        fprintf(stderr, "Codec not found\n");
        exit(1);
    }

    c = avcodec_alloc_context3(codec);
    if (!c) {
        fprintf(stderr, "Could not allocate audio codec context\n");
        exit(1);
    }

    /* put sample parameters */
    c->bit_rate = 64000;

    /* check that the encoder supports s16 pcm input */
    c->sample_fmt = AV_SAMPLE_FMT_S16;
    if (!check_sample_fmt(codec, c->sample_fmt)) {
        fprintf(stderr, "Encoder does not support sample format %s",
                av_get_sample_fmt_name(c->sample_fmt));
        exit(1);
    }

    /* select other audio parameters supported by the encoder */
    c->sample_rate    = select_sample_rate(codec);
    c->channel_layout = select_channel_layout(codec);
    c->channels       = av_get_channel_layout_nb_channels(c->channel_layout);

    /* open it */
    if (avcodec_open2(c, codec, NULL) < 0) {
        fprintf(stderr, "Could not open codec\n");
        exit(1);
    }

    f = fopen(filename, "wb");
    if (!f) {
        fprintf(stderr, "Could not open %s\n", filename);
        exit(1);
    }

    /* frame containing input raw audio */
    frame = avcodec_alloc_frame();
    if (!frame) {
        fprintf(stderr, "Could not allocate audio frame\n");
        exit(1);
    }

    frame->nb_samples     = c->frame_size;
    frame->format         = c->sample_fmt;
    frame->channel_layout = c->channel_layout;

    /* the codec gives us the frame size, in samples,
     * we calculate the size of the samples buffer in bytes */
    buffer_size = av_samples_get_buffer_size(NULL, c->channels, c->frame_size,
                                             c->sample_fmt, 0);
    samples = av_malloc(buffer_size);
    if (!samples) {
        fprintf(stderr, "Could not allocate %d bytes for samples buffer\n",
                buffer_size);
        exit(1);
    }
    /* setup the data pointers in the AVFrame */
    ret = avcodec_fill_audio_frame(frame, c->channels, c->sample_fmt,
                                   (const uint8_t*)samples, buffer_size, 0);
    if (ret < 0) {
        fprintf(stderr, "Could not setup audio frame\n");
        exit(1);
    }

    /* encode a single tone sound */
    t = 0;
    tincr = 2 * M_PI * 440.0 / c->sample_rate;
    for(i=0;i<200;i++) {
        av_init_packet(&pkt);
        pkt.data = NULL; // packet data will be allocated by the encoder
        pkt.size = 0;

        for (j = 0; j < c->frame_size; j++) {
            samples[2*j] = (int)(sin(t) * 10000);

            for (k = 1; k < c->channels; k++)
                samples[2*j + k] = samples[2*j];
            t += tincr;
        }
        /* encode the samples */
        ret = avcodec_encode_audio2(c, &pkt, frame, &got_output);
        if (ret < 0) {
            fprintf(stderr, "Error encoding audio frame\n");
            exit(1);
        }
        if (got_output) {
            fwrite(pkt.data, 1, pkt.size, f);
            av_free_packet(&pkt);
        }
    }

    /* get the delayed frames */
    for (got_output = 1; got_output; i++) {
        ret = avcodec_encode_audio2(c, &pkt, NULL, &got_output);
        if (ret < 0) {
            fprintf(stderr, "Error encoding frame\n");
            exit(1);
        }

        if (got_output) {
            fwrite(pkt.data, 1, pkt.size, f);
            av_free_packet(&pkt);
        }
    }
    fclose(f);

    av_freep(&samples);
    avcodec_free_frame(&frame);
    avcodec_close(c);
    av_free(c);
}

/*
 * Audio decoding.
 */
static void audio_decode_example(const char *outfilename, const char *filename)
{
    AVCodec *codec;
    AVCodecContext *c= NULL;
    int len;
    FILE *f, *outfile;
    uint8_t inbuf[AUDIO_INBUF_SIZE + FF_INPUT_BUFFER_PADDING_SIZE];
    AVPacket avpkt;
    AVFrame *decoded_frame = NULL;

    av_init_packet(&avpkt);

    printf("Decode audio file %s to %s\n", filename, outfilename);

    /* find the mpeg audio decoder */
    codec = avcodec_find_decoder(AV_CODEC_ID_MP2);
    if (!codec) {
        fprintf(stderr, "Codec not found\n");
        exit(1);
    }

    c = avcodec_alloc_context3(codec);
    if (!c) {
        fprintf(stderr, "Could not allocate audio codec context\n");
        exit(1);
    }

    /* open it */
    if (avcodec_open2(c, codec, NULL) < 0) {
        fprintf(stderr, "Could not open codec\n");
        exit(1);
    }

    f = fopen(filename, "rb");
    if (!f) {
        fprintf(stderr, "Could not open %s\n", filename);
        exit(1);
    }
    outfile = fopen(outfilename, "wb");
    if (!outfile) {
        av_free(c);
        exit(1);
    }

    /* decode until eof */
    avpkt.data = inbuf;
    avpkt.size = fread(inbuf, 1, AUDIO_INBUF_SIZE, f);

    while (avpkt.size > 0) {
        int got_frame = 0;

        if (!decoded_frame) {
            if (!(decoded_frame = avcodec_alloc_frame())) {
                fprintf(stderr, "Could not allocate audio frame\n");
                exit(1);
            }
        } else
            avcodec_get_frame_defaults(decoded_frame);

        len = avcodec_decode_audio4(c, decoded_frame, &got_frame, &avpkt);
        if (len < 0) {
            fprintf(stderr, "Error while decoding\n");
            exit(1);
        }
        if (got_frame) {
            /* if a frame has been decoded, output it */
            int data_size = av_samples_get_buffer_size(NULL, c->channels,
                                                       decoded_frame->nb_samples,
                                                       c->sample_fmt, 1);
            fwrite(decoded_frame->data[0], 1, data_size, outfile);
        }
        avpkt.size -= len;
        avpkt.data += len;
        avpkt.dts =
        avpkt.pts = AV_NOPTS_VALUE;
        if (avpkt.size < AUDIO_REFILL_THRESH) {
            /* Refill the input buffer, to avoid trying to decode
             * incomplete frames. Instead of this, one could also use
             * a parser, or use a proper container format through
             * libavformat. */
            memmove(inbuf, avpkt.data, avpkt.size);
            avpkt.data = inbuf;
            len = fread(avpkt.data + avpkt.size, 1,
                        AUDIO_INBUF_SIZE - avpkt.size, f);
            if (len > 0)
                avpkt.size += len;
        }
    }

    fclose(outfile);
    fclose(f);

    avcodec_close(c);
    av_free(c);
    avcodec_free_frame(&decoded_frame);
}

/*
 * Video encoding example
 */
static void video_encode_example(const char *filename, int codec_id)
{
    AVCodec *codec;
    AVCodecContext *c= NULL;
    int i, ret, x, y, got_output;
    FILE *f;
    AVFrame *frame;
    AVPacket pkt;
    uint8_t endcode[] = { 0, 0, 1, 0xb7 };

    printf("Encode video file %s\n", filename);

    /* find the mpeg1 video encoder */
    codec = avcodec_find_encoder(codec_id);
    if (!codec) {
        fprintf(stderr, "Codec not found\n");
        exit(1);
    }

    c = avcodec_alloc_context3(codec);
    if (!c) {
        fprintf(stderr, "Could not allocate video codec context\n");
        exit(1);
    }

    /* put sample parameters */
    c->bit_rate = 400000;
    /* resolution must be a multiple of two */
    c->width = 352;
    c->height = 288;
    /* frames per second */
    c->time_base= (AVRational){1,25};
    c->gop_size = 10; /* emit one intra frame every ten frames */
    c->max_b_frames=1;
    c->pix_fmt = AV_PIX_FMT_YUV420P;

    if(codec_id == AV_CODEC_ID_H264)
        av_opt_set(c->priv_data, "preset", "slow", 0);

    /* open it */
    if (avcodec_open2(c, codec, NULL) < 0) {
        fprintf(stderr, "Could not open codec\n");
        exit(1);
    }

    f = fopen(filename, "wb");
    if (!f) {
        fprintf(stderr, "Could not open %s\n", filename);
        exit(1);
    }

    frame = avcodec_alloc_frame();
    if (!frame) {
        fprintf(stderr, "Could not allocate video frame\n");
        exit(1);
    }
    frame->format = c->pix_fmt;
    frame->width  = c->width;
    frame->height = c->height;

    /* the image can be allocated by any means and av_image_alloc() is
     * just the most convenient way if av_malloc() is to be used */
    ret = av_image_alloc(frame->data, frame->linesize, c->width, c->height,
                         c->pix_fmt, 32);
    if (ret < 0) {
        fprintf(stderr, "Could not allocate raw picture buffer\n");
        exit(1);
    }

    /* encode 1 second of video */
    for(i=0;i<25;i++) {
        av_init_packet(&pkt);
        pkt.data = NULL;    // packet data will be allocated by the encoder
        pkt.size = 0;

        fflush(stdout);
        /* prepare a dummy image */
        /* Y */
        for(y=0;y<c->height;y++) {
            for(x=0;x<c->width;x++) {
                frame->data[0][y * frame->linesize[0] + x] = x + y + i * 3;
            }
        }

        /* Cb and Cr */
        for(y=0;y<c->height/2;y++) {
            for(x=0;x<c->width/2;x++) {
                frame->data[1][y * frame->linesize[1] + x] = 128 + y + i * 2;
                frame->data[2][y * frame->linesize[2] + x] = 64 + x + i * 5;
            }
        }

        frame->pts = i;

        /* encode the image */
        ret = avcodec_encode_video2(c, &pkt, frame, &got_output);
        if (ret < 0) {
            fprintf(stderr, "Error encoding frame\n");
            exit(1);
        }

        if (got_output) {
            printf("Write frame %3d (size=%5d)\n", i, pkt.size);
            fwrite(pkt.data, 1, pkt.size, f);
            av_free_packet(&pkt);
        }
    }

    /* get the delayed frames */
    for (got_output = 1; got_output; i++) {
        fflush(stdout);

        ret = avcodec_encode_video2(c, &pkt, NULL, &got_output);
        if (ret < 0) {
            fprintf(stderr, "Error encoding frame\n");
            exit(1);
        }

        if (got_output) {
            printf("Write frame %3d (size=%5d)\n", i, pkt.size);
            fwrite(pkt.data, 1, pkt.size, f);
            av_free_packet(&pkt);
        }
    }

    /* add sequence end code to have a real mpeg file */
    fwrite(endcode, 1, sizeof(endcode), f);
    fclose(f);

    avcodec_close(c);
    av_free(c);
    av_freep(&frame->data[0]);
    avcodec_free_frame(&frame);
    printf("\n");
}

/*
 * Video decoding example
 */

static void pgm_save(unsigned char *buf, int wrap, int xsize, int ysize,
                     char *filename)
{
    FILE *f;
    int i;

    f=fopen(filename,"w");
    fprintf(f,"P5\n%d %d\n%d\n",xsize,ysize,255);
    for(i=0;i<ysize;i++)
        fwrite(buf + i * wrap,1,xsize,f);
    fclose(f);
}

static int decode_write_frame(const char *outfilename, AVCodecContext *avctx,
                              AVFrame *frame, int *frame_count, AVPacket *pkt, int last)
{
    int len, got_frame;
    char buf[1024];

    len = avcodec_decode_video2(avctx, frame, &got_frame, pkt);
    if (len < 0) {
        fprintf(stderr, "Error while decoding frame %d\n", *frame_count);
        return len;
    }
    if (got_frame) {
        printf("Saving %sframe %3d\n", last ? "last " : "", *frame_count);
        fflush(stdout);

        /* the picture is allocated by the decoder, no need to free it */
        snprintf(buf, sizeof(buf), outfilename, *frame_count);
        pgm_save(frame->data[0], frame->linesize[0],
                 avctx->width, avctx->height, buf);
        (*frame_count)++;
    }
    if (pkt->data) {
        pkt->size -= len;
        pkt->data += len;
    }
    return 0;
}

static void video_decode_example(const char *outfilename, const char *filename)
{
    AVCodec *codec;
    AVCodecContext *c= NULL;
    int frame_count;
    FILE *f;
    AVFrame *frame;
    uint8_t inbuf[INBUF_SIZE + FF_INPUT_BUFFER_PADDING_SIZE];
    AVPacket avpkt;

    av_init_packet(&avpkt);

    /* set end of buffer to 0 (this ensures that no overreading happens for damaged mpeg streams) */
    memset(inbuf + INBUF_SIZE, 0, FF_INPUT_BUFFER_PADDING_SIZE);

    printf("Decode video file %s to %s\n", filename, outfilename);

    /* find the mpeg1 video decoder */
    codec = avcodec_find_decoder(AV_CODEC_ID_MPEG1VIDEO);
    if (!codec) {
        fprintf(stderr, "Codec not found\n");
        exit(1);
    }

    c = avcodec_alloc_context3(codec);
    if (!c) {
        fprintf(stderr, "Could not allocate video codec context\n");
        exit(1);
    }

    if(codec->capabilities&CODEC_CAP_TRUNCATED)
        c->flags|= CODEC_FLAG_TRUNCATED; /* we do not send complete frames */

    /* For some codecs, such as msmpeg4 and mpeg4, width and height
       MUST be initialized there because this information is not
       available in the bitstream. */

    /* open it */
    if (avcodec_open2(c, codec, NULL) < 0) {
        fprintf(stderr, "Could not open codec\n");
        exit(1);
    }

    f = fopen(filename, "rb");
    if (!f) {
        fprintf(stderr, "Could not open %s\n", filename);
        exit(1);
    }

    frame = avcodec_alloc_frame();
    if (!frame) {
        fprintf(stderr, "Could not allocate video frame\n");
        exit(1);
    }

    frame_count = 0;
    for(;;) {
        avpkt.size = fread(inbuf, 1, INBUF_SIZE, f);
        if (avpkt.size == 0)
            break;

        /* NOTE1: some codecs are stream based (mpegvideo, mpegaudio)
           and this is the only method to use them because you cannot
           know the compressed data size before analysing it.

           BUT some other codecs (msmpeg4, mpeg4) are inherently frame
           based, so you must call them with all the data for one
           frame exactly. You must also initialize 'width' and
           'height' before initializing them. */

        /* NOTE2: some codecs allow the raw parameters (frame size,
           sample rate) to be changed at any frame. We handle this, so
           you should also take care of it */

        /* here, we use a stream based decoder (mpeg1video), so we
           feed decoder and see if it could decode a frame */
        avpkt.data = inbuf;
        while (avpkt.size > 0)
            if (decode_write_frame(outfilename, c, frame, &frame_count, &avpkt, 0) < 0)
                exit(1);
    }

    /* some codecs, such as MPEG, transmit the I and P frame with a
       latency of one frame. You must do the following to have a
       chance to get the last frame of the video */
    avpkt.data = NULL;
    avpkt.size = 0;
    decode_write_frame(outfilename, c, frame, &frame_count, &avpkt, 1);

    fclose(f);

    avcodec_close(c);
    av_free(c);
    avcodec_free_frame(&frame);
    printf("\n");
}

int main(int argc, char **argv)
{
    const char *output_type;

    /* register all the codecs */
    avcodec_register_all();

    if (argc < 2) {
        printf("usage: %s output_type\n"
               "API example program to decode/encode a media stream with libavcodec.\n"
               "This program generates a synthetic stream and encodes it to a file\n"
               "named test.h264, test.mp2 or test.mpg depending on output_type.\n"
               "The encoded stream is then decoded and written to a raw data output.\n"
               "output_type must be choosen between 'h264', 'mp2', 'mpg'.\n",
               argv[0]);
        return 1;
    }
    output_type = argv[1];

    if (!strcmp(output_type, "h264")) {
        video_encode_example("test.h264", AV_CODEC_ID_H264);
    } else if (!strcmp(output_type, "mp2")) {
        audio_encode_example("test.mp2");
        audio_decode_example("test.sw", "test.mp2");
    } else if (!strcmp(output_type, "mpg")) {
        video_encode_example("test.mpg", AV_CODEC_ID_MPEG1VIDEO);
        video_decode_example("test%02d.pgm", "test.mpg");
    } else {
        fprintf(stderr, "Invalid output type '%s', choose between 'h264', 'mp2', or 'mpg'\n",
                output_type);
        return 1;
    }

    return 0;
}


=====================

// ffmpeg_sample.c
// Date: Sep 05, 2013
// Code based on a https://raw.github.com/phamquy/FFmpeg-tutorial-samples/master/tutorial01.c
// Tested on CentOS 5.7, GCC 4.1.2,FFMPEG 0.10.1
// libavcodec.so.53.60.100  libavdevice.so.53.4.100  libavfilter.so.2.60.100
// libavformat.so.53.31.100  libavutil.so.51.34.101  libswresample.so.0.6.100
// libswscale.so.2.1.100
//
// A small sample program that shows how to use libavformat to decode a video file and save it as Y frames.
//
// Build (assuming libavformat, libavcodec, libavutils are correctly installed on your system).
//
// gcc -o sample ffmpeg_sample.c -lavformat
//
// Run using
//
// ./sample myvideofile.mpg
//
// To view the generated output
//
// mplayer -demuxer rawvideo -rawvideo w=[LINESIZE]:h=[HEIGHT]:format=y8 out.raw -loop 0

#include
#include

int readsave_frames(int videoStreamIdx
                , AVFormatContext *pFormatCtx
                , AVCodecContext  *pCodecCtx
                , AVCodec         *pCodec
)
{
    int             y, i;
    FILE           *pFile;
    AVPacket        packet;
    int             frameFinished;
    AVFrame        *pFrame;


    // Open file
    pFile=fopen("out.raw", "wb");
    if(pFile==NULL)
    {
        printf("Unable to open output file\n");
        return -1;
    }

    /// Allocate video frame
    pFrame = avcodec_alloc_frame();

    printf("\n");
    for(i=0; av_read_frame(pFormatCtx, &packet) >= 0;) {

        // Is this a packet from the video stream?
        if(packet.stream_index==videoStreamIdx) {
            i++;

            /// Decode video frame
            avcodec_decode_video2(pCodecCtx, pFrame, &frameFinished, &packet);

            // Did we get a video frame?
            if(frameFinished) {
                printf("\rFrame [%d]: pts=%lld, pkt_pts=%lld, pkt_dts=%lld", i, pFrame->pts, pFrame->pkt_pts, pFrame->pkt_dts);
                // Write pixel data
                for(y=0; yheight; y++)
                    fwrite(pFrame->data[0]+y*pFrame->linesize[0], 1, pFrame->linesize[0], pFile);
            }
        }

        // Free the packet that was allocated by av_read_frame
        av_free_packet(&packet);
    }
    printf("\n");

    /// Free the Y frame
    av_free(pFrame);

    // Close file
    fclose(pFile);

    return 0;
}


int main(int argc, char *argv[]) {
    AVFormatContext *pFormatCtx;
    int             videoStreamIdx;
    AVCodecContext  *pCodecCtx;
    AVCodec         *pCodec;

    if(argc < 2) {
        printf("Please provide a movie file\n");
        return -1;
    }
    // Register all formats and codecs
    av_register_all();

    pFormatCtx = avformat_alloc_context();

    /// Open video file
    if(avformat_open_input(&pFormatCtx, argv[1], 0, NULL) != 0)
    {
        printf("avformat_open_input failed: Couldn't open file\n");
        return -1; // Couldn't open file
    }

    /// Retrieve stream information
    if(avformat_find_stream_info(pFormatCtx, NULL) < 0)
    {
        printf("avformat_find_stream_info failed: Couldn't find stream information\n");
        return -1; // Couldn't find stream information
    }

    /// Dump information about file onto standard error
    av_dump_format(pFormatCtx, 0, argv[1], 0);


    /// Find the first video stream
    {
        int i = 0;
        videoStreamIdx=-1;
        for(i=0; inb_streams; i++)
        {
            if(pFormatCtx->streams[i]->codec->codec_type == AVMEDIA_TYPE_VIDEO) { //CODEC_TYPE_VIDEO
                videoStreamIdx=i;
                break;
            }
        }
    }
    /// Check if video stream is found
    if(videoStreamIdx==-1)
        return -1; // Didn't find a video stream


    /// Get a pointer to the codec context for the video stream
    pCodecCtx = pFormatCtx->streams[videoStreamIdx]->codec;


    /// Find the decoder for the video stream
    pCodec = avcodec_find_decoder( pCodecCtx->codec_id);
    if(pCodec==NULL) {
        fprintf(stderr, "Unsupported codec!\n");
        return -1; // Codec not found
    }

    /// Open codec
    if( avcodec_open2(pCodecCtx, pCodec, NULL) < 0 )
        return -1; // Could not open codec

    // Read frames and save them to disk
    if ( readsave_frames(videoStreamIdx, pFormatCtx, pCodecCtx, pCodec) < 0)
    {
        return -1;
    }

    /// Close the codec
    avcodec_close(pCodecCtx);

    /// Close the video file
    avformat_close_input(&pFormatCtx);
0
    return 0;
}
=========================
network stream


char * url = "udp://:1500";
char * format = "mpegts";

AVInputFormat *fmt = NULL;
AVFormatContext *oc = NULL;

int res;

if (format != NULL){
fmt = av_find_input_format(format);
res = avformat_open_input(&oc, url, fmt , NULL);
} else {
res = avformat_open_input(&oc, url, NULL , NULL);
}

So it may be just a matter of supplying the format (its normally mpegts for udp streams).


============================
